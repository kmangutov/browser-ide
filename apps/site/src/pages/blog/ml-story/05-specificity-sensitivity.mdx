---
layout: ../../../layouts/BlogPostLayout.astro
title: "Specificity vs Sensitivity: Medical Perspectives"
description: "How different domains reframe the evaluation of models"
pubDate: "April 4 2023"
---

# Specificity vs Sensitivity: A Medical Lens

## In domains like medicine, these values become life and death
When a doctor orders a test, two questions loom: "If someone has the disease, will the test detect it?" (sensitivity) and "If someone doesn't have the disease, will the test correctly rule it out?" (specificity). These questions directly map to recall and precision but are framed from the perspective of the medical field where the stakes can be extraordinarily high.

{/* TODO: Add Manim animation showing a medical screening process and how sensitivity and specificity affect outcomes */}

## Mirrors precision/recall but emphasizes the perspective of absence
While recall (sensitivity) focuses on correctly identifying positive cases, specificity highlights the importance of correctly identifying negative cases. This shift in perspective is crucial in contexts where ruling out a condition is as important as identifying it. Sensitivity answers "How good is this test at finding the disease?" while specificity answers "How good is this test at ruling out the disease in healthy individuals?"

{/* TODO: Add interactive Python snippet demonstrating the calculation of sensitivity and specificity for a medical test */}

## The ROC curve: visualizing the trade-off
The Receiver Operating Characteristic (ROC) curve plots sensitivity against (1-specificity), providing a visual representation of the trade-off as we adjust the decision threshold. The area under this curve (AUC) gives us a single metric that captures how well our model can distinguish between classes, regardless of the threshold chosen.

{/* TODO: Add Manim animation showing how an ROC curve is constructed and what different curve shapes mean */}

The language of specificity and sensitivity raises an important question: how does the nature of what we're predicting—categories or continuous values—affect how we evaluate and train our models? This brings us to our next topic: **Categorical vs Continuous Loss**. 