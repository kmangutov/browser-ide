<!DOCTYPE html><html lang="en" data-astro-cid-37fxchfa> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Understanding the trade-offs in what we optimize for"><title>Precision vs Recall: The Values We Choose</title><link rel="stylesheet" href="/browser-ide/assets/creating-pyodide-animations-D13ptpoQ.css">
<link rel="stylesheet" href="/browser-ide/assets/creating-pyodide-animations-3o92PDWl.css"></head> <body data-astro-cid-37fxchfa> <!-- Navigation Bar --> <nav class="main-nav" data-astro-cid-37fxchfa> <ul data-astro-cid-37fxchfa> <li data-astro-cid-37fxchfa><a href="/browser-ide" class="" data-astro-cid-37fxchfa>Playground</a></li> <li data-astro-cid-37fxchfa><a href="/browser-ide/blog/" class="" data-astro-cid-37fxchfa>Blog</a></li> </ul> </nav> <main class="content" data-astro-cid-37fxchfa>  <article data-astro-cid-2q5oecfc> <header data-astro-cid-2q5oecfc> <h1 data-astro-cid-2q5oecfc>Precision vs Recall: The Values We Choose</h1>  </header> <div class="prose" data-astro-cid-2q5oecfc> <h1 id="precision-vs-recall-what-matters-most">Precision vs Recall: What Matters Most?</h1>
<h2 id="in-choosing-whats-important-to-get-right-we-define-our-values">In choosing what’s important to get right, we define our values</h2>
<p>Not all errors are created equal. When we build models to make decisions, we implicitly encode value judgments about which kinds of mistakes are more acceptable. In classification problems, we face a fundamental choice: do we prioritize being right when we make a positive prediction (precision), or do we focus on catching as many positive cases as possible (recall)?</p>

<h2 id="a-tension-emerges-do-we-cry-wolf-or-miss-the-threat">A tension emerges: do we cry wolf or miss the threat?</h2>
<p>Precision and recall often exist in tension with each other. As we adjust our model to increase precision (reducing false alarms), we typically sacrifice recall (missing more actual cases). Conversely, as we increase recall to catch more positive cases, we tend to generate more false positives.</p>

<h2 id="contextualizes-error-into-decision-making-under-uncertainty">Contextualizes error into decision-making under uncertainty</h2>
<p>This trade-off forces us to think about the real-world context of our model’s applications. In medical diagnosis, missing a disease (false negative) might be life-threatening, while in spam detection, incorrectly flagging a legitimate email (false positive) might be more problematic than missing some spam.</p>

<p>The precision-recall framework introduces us to thinking about model evaluation in terms of specific kinds of errors. This perspective is particularly important in certain domains, which leads us to our next topic: <strong>Specificity vs Sensitivity</strong>.</p> </div> </article>   </main> </body></html>